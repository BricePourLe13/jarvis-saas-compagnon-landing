/**
 * üéôÔ∏è CONFIGURATION CENTRALIS√âE OPENAI REALTIME
 * 
 * IMPORTANT:
 * - Tous les mod√®les et configurations audio sont d√©finis ici
 * - Les valeurs par d√©faut utilisent les derniers mod√®les stables (2025)
 * - Modifiable via variables d'environnement pour flexibilit√©
 * 
 * USAGE:
 * ```typescript
 * import { OPENAI_CONFIG } from '@/lib/openai-config'
 * 
 * const sessionConfig = {
 *   model: OPENAI_CONFIG.models.production,
 *   voice: OPENAI_CONFIG.voices.production,
 *   // ...
 * }
 * ```
 * 
 * @version 2.0.0
 * @date 2025-10-22
 */

export const OPENAI_CONFIG = {
  /**
   * ü§ñ MOD√àLES REALTIME
   * 
   * - production: Optimis√© co√ªt/qualit√© pour usage quotidien
   * - vitrine: Meilleure qualit√© pour d√©mos commerciales
   * - audio: Mod√®le sp√©cialis√© audio (√† tester)
   */
  models: {
    /**
     * Mod√®le production (kiosques, app mobile)
     * - Mini = optimis√© co√ªt
     * - Bonne qualit√© pour fitness coaching
     * - Latence <800ms
     */
    production: process.env.OPENAI_REALTIME_MODEL_PROD || 'gpt-realtime-mini-2025-10-06',
    
    /**
     * Mod√®le vitrine (d√©mos commerciales, landing page)
     * - gpt-realtime-2025-08-28 = Mod√®le GA officiel (doc actualis√©e nov 2025)
     * - Format GA (pas de header OpenAI-Beta)
     */
    vitrine: process.env.OPENAI_REALTIME_MODEL_VITRINE || 'gpt-realtime-2025-08-28',
    
    /**
     * Mod√®le audio sp√©cialis√© (√† √©valuer)
     * - Potentiellement optimis√© pour audio-only
     * - √Ä tester pour co√ªt/qualit√©
     */
    audio: process.env.OPENAI_REALTIME_MODEL_AUDIO || 'gpt-audio-2025-08-28',
  },

  /**
   * üé§ VOIX TTS
   * 
   * Voix test√©es et valid√©es pour le fran√ßais:
   * - verse: Optimis√©e fran√ßais (naturelle, expressive)
   * - alloy: Voix masculine √©nergique (alternative)
   * - ballad, coral, sage: Autres options (√† tester)
   */
  voices: {
    /**
     * Voix production
     * - verse = voix fran√ßaise optimis√©e
     * - Ton naturel et bienveillant pour coaching
     */
    production: (process.env.OPENAI_VOICE_PROD || 'verse') as OpenAIVoice,
    
    /**
     * Voix vitrine
     * - shimmer = voix f√©minine √©nergique et claire
     * - Ton commercial et engageant
     */
    vitrine: (process.env.OPENAI_VOICE_VITRINE || 'shimmer') as OpenAIVoice,
    
    /**
     * Voix fallback (si voix principale indisponible)
     */
    fallback: (process.env.OPENAI_VOICE_FALLBACK || 'alloy') as OpenAIVoice,
  },

  /**
   * üéß CONFIGURATION AUDIO
   * 
   * Format optimis√© pour WebRTC et faible latence
   */
  audio: {
    /**
     * Format d'entr√©e (microphone)
     * - pcm16 = 16-bit PCM (standard WebRTC)
     * - 16kHz mono
     */
    inputFormat: 'pcm16' as const,
    
    /**
     * Format de sortie (haut-parleurs)
     * - pcm16 = 16-bit PCM (standard WebRTC)
     * - 16kHz mono
     */
    outputFormat: 'pcm16' as const,
    
    /**
     * Taux d'√©chantillonnage
     * - 16kHz = bon compromis qualit√©/bande passante
     * - Compatible avec tous les navigateurs modernes
     */
    sampleRate: 16000,
  },

  /**
   * üéôÔ∏è VOICE ACTIVITY DETECTION (VAD)
   * 
   * Configuration server-side VAD pour d√©tection de parole
   */
  vad: {
    /**
     * Type de VAD
     * - server_vad = d√©tection c√¥t√© serveur OpenAI (recommand√©)
     * - √âvite la charge CPU client
     */
    type: 'server_vad' as const,
    
    /**
     * Seuil de d√©tection
     * - 0.5 = √©quilibr√© (ni trop sensible, ni trop sourd)
     * - Range: 0.0 (tr√®s sensible) √† 1.0 (tr√®s sourd)
     */
    threshold: 0.5,
    
    /**
     * Padding avant la parole (ms)
     * - 300ms = capture le d√©but de mots
     * - √âvite de couper le premier phon√®me
     */
    prefixPaddingMs: 300,
    
    /**
     * Dur√©e de silence pour fin de tour (PRODUCTION)
     * - 500ms = r√©actif pour coaching fitness
     * - Bon compromis vitesse/confort
     */
    silenceDurationMs: 500,
    
    /**
     * Dur√©e de silence pour fin de tour (D√âMO/VITRINE)
     * - 1200ms = plus tol√©rant pour h√©sitations commerciales
     * - √âvite interruptions g√™nantes en d√©mo
     */
    silenceDurationMsDemo: 1200,
    
    /**
     * Autoriser interruptions utilisateur
     * - true = utilisateur peut couper JARVIS (naturel)
     * - false = JARVIS finit toujours sa phrase
     */
    interruptResponse: true,
    
    /**
     * Cr√©er r√©ponse automatiquement apr√®s d√©tection
     * - true = LLM g√©n√®re r√©ponse d√®s silence d√©tect√©
     * - false = requiert trigger manuel (pas recommand√©)
     */
    createResponse: true,
  },

  /**
   * üì° URLS API OPENAI (FORMAT GA 2025)
   */
  api: {
    /**
     * URL cr√©ation client secrets (ephemeral tokens) - FORMAT GA
     * Doc ligne 336: "POST /v1/realtime/client_secrets"
     * https://platform.openai.com/docs/api-reference/realtime-sessions/create-realtime-client-secret
     */
    clientSecrets: 'https://api.openai.com/v1/realtime/client_secrets',
    
    /**
     * URL WebRTC calls (FORMAT GA - chang√© de /realtime vers /realtime/calls)
     * Doc ligne 368-370: "New URL for WebRTC SDP data"
     * https://platform.openai.com/docs/guides/realtime-webrtc#connecting-using-the-unified-interface
     */
    realtimeCalls: 'https://api.openai.com/v1/realtime/calls',
    
    /**
     * ‚ùå DEPRECATED - Ne plus utiliser le header Beta pour mod√®les GA
     * (N√©cessaire uniquement si utilisation mod√®les beta avec OpenAI-Beta: realtime=v1)
     */
    betaHeader: 'realtime=v1', // ‚ùå Ne pas utiliser pour gpt-realtime-2025-08-28
  },

  /**
   * ‚öôÔ∏è CONFIGURATION SESSION PAR D√âFAUT
   * 
   * Utilis√© comme base pour toutes les sessions
   */
  session: {
    /**
     * Temp√©rature du LLM
     * - 0.8 = cr√©atif sans √™tre trop al√©atoire
     * - Range: 0.0 (d√©terministe) √† 2.0 (tr√®s cr√©atif)
     */
    temperature: 0.8,
    
    /**
     * Tokens max de sortie
     * - 4096 = permet r√©ponses d√©taill√©es si besoin
     * - JARVIS reste concis naturellement (via instructions)
     */
    maxResponseOutputTokens: 4096,
    
    /**
     * Mod√®le de transcription (STT int√©gr√©)
     * - whisper-1 = mod√®le OpenAI Whisper standard
     * - Tr√®s bon pour le fran√ßais
     */
    transcriptionModel: 'whisper-1',
  },
} as const

/**
 * üé≠ TYPES TYPESCRIPT
 */

/**
 * Voix disponibles dans OpenAI Realtime API
 * 
 * Source: https://platform.openai.com/docs/guides/realtime
 * 
 * - alloy: Voix neutre, √©nergique
 * - ash: Voix masculine mature (nouvelle)
 * - ballad: Voix douce, chaleureuse
 * - coral: Voix f√©minine expressive
 * - echo: Voix masculine (classique)
 * - sage: Voix m√ªre, autoritaire
 * - shimmer: Voix douce, calme
 * - verse: Voix optimis√©e fran√ßais (recommand√©e FR)
 */
export type OpenAIVoice = 
  | 'alloy'
  | 'ash'
  | 'ballad'
  | 'coral'
  | 'echo'
  | 'sage'
  | 'shimmer'
  | 'verse'

/**
 * Mod√®les Realtime disponibles
 */
export type OpenAIRealtimeModel = 
  | 'gpt-realtime-2025-08-28'           // Full - haute qualit√©
  | 'gpt-realtime-mini-2025-10-06'      // Mini - optimis√© co√ªt
  | 'gpt-audio-2025-08-28'              // Audio sp√©cialis√©

/**
 * Types de contexte (production vs vitrine)
 */
export type OpenAIContext = 'production' | 'vitrine' | 'audio'

/**
 * üîß HELPER FUNCTIONS
 */

/**
 * R√©cup√©rer configuration pour un contexte sp√©cifique
 * 
 * @param context Type de session (production, vitrine, audio)
 * @returns Configuration compl√®te pour ce contexte
 * 
 * @example
 * ```typescript
 * const config = getConfigForContext('production')
 * // config.model = 'gpt-realtime-mini-2025-10-06'
 * // config.voice = 'verse'
 * // config.vad.silenceDurationMs = 500
 * ```
 */
export function getConfigForContext(context: OpenAIContext) {
  const isDemo = context === 'vitrine'
  
  return {
    model: OPENAI_CONFIG.models[context],
    voice: context === 'production' ? OPENAI_CONFIG.voices.production : OPENAI_CONFIG.voices.vitrine,
    input_audio_format: OPENAI_CONFIG.audio.inputFormat,
    output_audio_format: OPENAI_CONFIG.audio.outputFormat,
    modalities: ['audio'], // ‚úÖ Speech-to-speech : ['audio'] uniquement (doc ligne 1202-1203)
    turn_detection: {
      type: OPENAI_CONFIG.vad.type,
      threshold: isDemo ? 0.3 : OPENAI_CONFIG.vad.threshold, // ‚úÖ Plus sensible pour vitrine (0.3 vs 0.5)
      prefix_padding_ms: OPENAI_CONFIG.vad.prefixPaddingMs,
      silence_duration_ms: isDemo ? OPENAI_CONFIG.vad.silenceDurationMsDemo : OPENAI_CONFIG.vad.silenceDurationMs,
      interrupt_response: OPENAI_CONFIG.vad.interruptResponse,
      create_response: OPENAI_CONFIG.vad.createResponse,
    },
    input_audio_transcription: {
      model: OPENAI_CONFIG.session.transcriptionModel,
      language: 'fr', // ‚úÖ Forcer fran√ßais (√©vite d√©tection automatique incorrecte)
    },
    temperature: OPENAI_CONFIG.session.temperature,
    max_response_output_tokens: OPENAI_CONFIG.session.maxResponseOutputTokens,
  }
}

/**
 * üîë Cr√©er config MINIMALE pour ephemeral token
 * 
 * L'endpoint /v1/realtime/client_secrets N'ACCEPTE QUE la config minimale.
 * Les instructions, tools, etc. doivent √™tre envoy√©s APR√àS via session.update.
 * 
 * @param context Type de session (production, vitrine, audio)
 * @returns Configuration minimale pour cr√©er l'ephemeral token
 * 
 * @example
 * ```typescript
 * const minimalConfig = getMinimalSessionConfig('vitrine')
 * // { type: "realtime", model: "gpt-realtime-2025-08-28", audio: { output: { voice: "alloy" } } }
 * ```
 * 
 * Doc r√©f√©rence: https://platform.openai.com/docs/guides/realtime-webrtc (ligne 634-644)
 * Structure accept√©e par /client_secrets :
 * ```
 * {
 *   type: "realtime",
 *   model: "gpt-realtime",
 *   audio: {
 *     output: { voice: "marin" }
 *   }
 * }
 * ```
 */
export function getMinimalSessionConfig(context: OpenAIContext) {
  return {
    type: "realtime" as const,
    model: OPENAI_CONFIG.models[context],
    audio: {
      output: {
        voice: context === 'production' ? OPENAI_CONFIG.voices.production : OPENAI_CONFIG.voices.vitrine
      }
    }
  }
}

/**
 * üéõÔ∏è Cr√©er config COMPL√àTE pour session.update
 * 
 * Cette config est envoy√©e APR√àS la connexion WebRTC via le data channel
 * avec un √©v√©nement `session.update`.
 * 
 * @param config Configuration retourn√©e par getConfigForContext()
 * @param instructions Instructions syst√®me pour le LLM
 * @param tools Fonctions disponibles (optionnel)
 * @returns Configuration compl√®te pour session.update
 * 
 * @example
 * ```typescript
 * const baseConfig = getConfigForContext('vitrine')
 * const sessionUpdate = getFullSessionUpdate(baseConfig, instructions, tools)
 * 
 * // Envoyer via WebRTC data channel :
 * dataChannel.send(JSON.stringify({
 *   type: 'session.update',
 *   session: sessionUpdate
 * }))
 * ```
 * 
 * Doc r√©f√©rence: https://platform.openai.com/docs/guides/realtime-webrtc
 */
export function getFullSessionUpdate(
  config: ReturnType<typeof getConfigForContext>,
  instructions: string,
  tools?: any[],
  voice?: OpenAIVoice
) {
  // ‚úÖ Structure session.update selon doc OpenAI
  // https://platform.openai.com/docs/guides/realtime-webrtc
  return {
    type: "realtime" as const,
    output_modalities: ['audio'] as const,
    audio: {
      input: {
        format: {
          type: "audio/pcm" as const,
          rate: 24000,  // ‚úÖ REQUIS pour input
        },
        turn_detection: config.turn_detection,
      },
      output: {
        format: {
          type: "audio/pcm" as const,
          rate: 24000,  // ‚úÖ REQUIS selon erreur OpenAI
        },
        voice: voice || config.voice
      },
    },
    instructions,
    tools: tools || [],
    tool_choice: tools && tools.length > 0 ? 'auto' : undefined,
  }
}

/**
 * Construire URL WebRTC pour format GA
 * 
 * @param context Type de session
 * @returns URL pour connexion WebRTC (format GA - /realtime/calls)
 * 
 * @example
 * ```typescript
 * const url = getRealtimeURL('production')
 * // 'https://api.openai.com/v1/realtime/calls'
 * ```
 * 
 * ‚ö†Ô∏è FORMAT GA : L'URL est maintenant /realtime/calls (pas de query param model)
 * Le mod√®le est sp√©cifi√© dans le sessionConfig lors de la cr√©ation de session
 * Doc: https://platform.openai.com/docs/guides/realtime-webrtc#connecting-using-the-unified-interface
 */
export function getRealtimeURL(context: OpenAIContext): string {
  // ‚úÖ FORMAT GA : Utiliser /realtime/calls sans query param
  return OPENAI_CONFIG.api.realtimeCalls
}

/**
 * V√©rifier si un mod√®le est disponible
 * 
 * @param model Nom du mod√®le √† v√©rifier
 * @returns true si mod√®le valide
 */
export function isValidModel(model: string): model is OpenAIRealtimeModel {
  const validModels: OpenAIRealtimeModel[] = [
    'gpt-realtime-2025-08-28',
    'gpt-realtime-mini-2025-10-06',
    'gpt-audio-2025-08-28',
  ]
  return validModels.includes(model as OpenAIRealtimeModel)
}

/**
 * V√©rifier si une voix est disponible
 * 
 * @param voice Nom de la voix √† v√©rifier
 * @returns true si voix valide
 */
export function isValidVoice(voice: string): voice is OpenAIVoice {
  const validVoices: OpenAIVoice[] = [
    'alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse'
  ]
  return validVoices.includes(voice as OpenAIVoice)
}

/**
 * üìä MONITORING HELPERS
 */

/**
 * Extraire version du mod√®le pour analytics
 * 
 * @param model Nom complet du mod√®le
 * @returns Version format√©e (ex: "2025-10", "2025-08")
 * 
 * @example
 * ```typescript
 * getModelVersion('gpt-realtime-mini-2025-10-06') // '2025-10'
 * getModelVersion('gpt-realtime-2025-08-28')      // '2025-08'
 * ```
 */
export function getModelVersion(model: string): string {
  const match = model.match(/(\d{4})-(\d{2})/)
  return match ? `${match[1]}-${match[2]}` : 'unknown'
}

/**
 * D√©terminer le tier du mod√®le pour analytics
 * 
 * @param model Nom complet du mod√®le
 * @returns Tier ('mini', 'full', 'audio', 'unknown')
 */
export function getModelTier(model: string): 'mini' | 'full' | 'audio' | 'unknown' {
  if (model.includes('mini')) return 'mini'
  if (model.includes('audio')) return 'audio'
  if (model.includes('realtime')) return 'full'
  return 'unknown'
}

/**
 * üîí VALIDATION RUNTIME
 * 
 * V√©rifier configuration au d√©marrage
 */
export function validateConfig(): { valid: boolean; errors: string[] } {
  const errors: string[] = []

  // V√©rifier mod√®les
  if (!isValidModel(OPENAI_CONFIG.models.production)) {
    errors.push(`Invalid production model: ${OPENAI_CONFIG.models.production}`)
  }
  if (!isValidModel(OPENAI_CONFIG.models.vitrine)) {
    errors.push(`Invalid vitrine model: ${OPENAI_CONFIG.models.vitrine}`)
  }
  if (!isValidModel(OPENAI_CONFIG.models.audio)) {
    errors.push(`Invalid audio model: ${OPENAI_CONFIG.models.audio}`)
  }

  // V√©rifier voix
  if (!isValidVoice(OPENAI_CONFIG.voices.production)) {
    errors.push(`Invalid production voice: ${OPENAI_CONFIG.voices.production}`)
  }
  if (!isValidVoice(OPENAI_CONFIG.voices.vitrine)) {
    errors.push(`Invalid vitrine voice: ${OPENAI_CONFIG.voices.vitrine}`)
  }
  if (!isValidVoice(OPENAI_CONFIG.voices.fallback)) {
    errors.push(`Invalid fallback voice: ${OPENAI_CONFIG.voices.fallback}`)
  }

  // V√©rifier VAD
  if (OPENAI_CONFIG.vad.threshold < 0 || OPENAI_CONFIG.vad.threshold > 1) {
    errors.push(`Invalid VAD threshold: ${OPENAI_CONFIG.vad.threshold} (must be 0-1)`)
  }

  return {
    valid: errors.length === 0,
    errors,
  }
}

// üöÄ Validation au chargement du module (dev only)
if (process.env.NODE_ENV === 'development') {
  const validation = validateConfig()
  if (!validation.valid) {
    console.warn('‚ö†Ô∏è OPENAI_CONFIG validation errors:', validation.errors)
  } else {
    console.log('‚úÖ OPENAI_CONFIG validated successfully')
    console.log('üìã Models:', OPENAI_CONFIG.models)
    console.log('üé§ Voices:', OPENAI_CONFIG.voices)
  }
}

